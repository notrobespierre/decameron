{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sathishkumar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ok first some imports\n",
    "import pyvis as pv \n",
    "import networkx as nx \n",
    "import pandas as pd\n",
    "import requests\n",
    "import scipy\n",
    "from bs4 import BeautifulSoup\n",
    "from pyvis.network import Network\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ed7315",
   "metadata": {},
   "source": [
    "Functions for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b25729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges_rey(graph, edges):\n",
    "    \"\"\"\n",
    "    This method serves to add multiple edges between existing nodes\n",
    "    in the network instance. Adding of the edges is done based off\n",
    "    of the IDs of the nodes. Order does not matter unless dealing with a\n",
    "    directed graph.\n",
    "\n",
    "    :param edges: A list of tuples, each tuple consists of source of edge,\n",
    "                  edge destination and and optional width.\n",
    "\n",
    "    :type arrowStrikethrough: list of tuples\n",
    "    \"\"\"\n",
    "    for edge in edges:\n",
    "        # if incoming tuple contains a weight\n",
    "        if len(edge) == 3:\n",
    "            graph.add_edge(edge[0], edge[1], color=edge[2], arrows = \"hi\")\n",
    "        else:\n",
    "            graph.add_edge(edge[0], edge[1])\n",
    "\n",
    "\n",
    "def connect_edges(edges_list, graph, color):\n",
    "    connect_list = [(story1, story2, color) for story1 in edges_list for story2 in edges_list if story1!=story2 and story1>story2]\n",
    "    print(connect_list)\n",
    "    add_edges_rey(graph, connect_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b431a6e7",
   "metadata": {},
   "source": [
    "Functions for text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb96bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_story(URL):\n",
    "\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    results = soup.find(id=\"container\")\n",
    "    main_text = results.find_all(\"p\")\n",
    "\n",
    "    full_story = \"\"\n",
    "    for element in main_text:\n",
    "        clean_element = element.text.strip()\n",
    "        clean_element = re.sub(r'[0-9]+', '', clean_element)\n",
    "        clean_element = re.sub(r'\\[|\\]|\\t|\\n', '', clean_element)\n",
    "        full_story += clean_element\n",
    "    return full_story\n",
    "\n",
    "def two_digit(digit):\n",
    "    if (digit < 10):\n",
    "        digit = f\"0{digit}\"\n",
    "    return str(digit)\n",
    "\n",
    "def return_URL(day, story):\n",
    "    story = two_digit(story)\n",
    "    day = two_digit(day)\n",
    "    URL = f\"https://www.brown.edu/Departments/Italian_Studies/dweb/texts/DecShowText.php?myID=nov{day}{story}&lang=eng\"\n",
    "    return URL\n",
    "\n",
    "def analyze_story():\n",
    "    #TODO\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c0c2039",
   "metadata": {},
   "source": [
    "## Graphing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b76b7152",
   "metadata": {},
   "source": [
    "### Colors and Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d56377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating storytellers colors\n",
    "storytellers = {\n",
    "    \"Panfilo\" : \"#9e0142\",\n",
    "    \"Neifile\" : \"#d53e4f\",\n",
    "    \"Filomena\" : \"#f46d43\",\n",
    "    \"Dioneo\" : \"#fdae61\",\n",
    "    \"Fiametta\" : \"#fee08b\",\n",
    "    \"Emilia\" : \"#e6f598\",\n",
    "    \"Filostrato\" : \"#abdda4\",\n",
    "    \"Lauretta\" : \"#66c2a5\",\n",
    "    \"Elissa\" : \"#3288bd\",\n",
    "    \"Pampinea\" : \"#5e4fa2\"\n",
    "}\n",
    "\n",
    "# themes\n",
    "\n",
    "THEMES = [\"Storytelling\", \"Cultural_Exchange\", \"Sexuality\", \"Gender_Bending\"]\n",
    "theme_dict = {}\n",
    "color_coding = {\n",
    "    \"Storytelling\" : \"blue\",\n",
    "    \"Cultural_Exchange\" : \"green\",\n",
    "    \"Sexuality\" : \"red\",\n",
    "    \"Gender_Bending\": \"purple\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "491c9a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30, 1, 'blue'), (30, 17, 'blue'), (30, 19, 'blue'), (30, 26, 'blue'), (17, 1, 'blue'), (19, 1, 'blue'), (19, 17, 'blue'), (26, 1, 'blue'), (26, 17, 'blue'), (26, 19, 'blue')]\n",
      "[(30, 3, 'green'), (30, 17, 'green'), (30, 19, 'green'), (17, 3, 'green'), (19, 3, 'green'), (19, 17, 'green')]\n",
      "[(30, 17, 'red'), (30, 26, 'red'), (26, 17, 'red')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## ACTUAL STUFF\n",
    "# read in data and create graph\n",
    "df = pd.read_csv(\"decameron_themes.csv\")\n",
    "main_graph = Network(directed = True)\n",
    "main_graph.set_edge_smooth(\"dynamic\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # this adds nodes to the graphs of each of the storytellers\n",
    "    main_graph.add_node(row[\"Story_Hash\"], label = f\"Day {row[\"Day\"]}, Story {row[\"Story\"]}\", color = storytellers[row[\"Storyteller\"]], title='<a href=\\'http://www.google.com\\'>google</a>')\n",
    "\n",
    "    # TODO main_graph[row[\"\"]= \n",
    "    #\n",
    "\n",
    "\n",
    "# creating theme lists\n",
    "for theme in THEMES:\n",
    "    theme_dict[theme] = df.loc[df[theme] == True][\"Story_Hash\"].tolist()\n",
    "    connect_edges(theme_dict[theme], main_graph, color_coding[theme])\n",
    "\n",
    "\n",
    "## OK LETS SEE THIS\n",
    "main_graph.barnes_hut(spring_length = 150)\n",
    "main_graph.show_buttons()\n",
    "main_graph.show(\"hello.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38de2d50",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140d5a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Scraping: Day 1, Story 1\n",
      "Currently Scraping: Day 1, Story 2\n",
      "Currently Scraping: Day 1, Story 3\n",
      "Currently Scraping: Day 1, Story 4\n",
      "Currently Scraping: Day 1, Story 5\n",
      "Currently Scraping: Day 1, Story 6\n",
      "Currently Scraping: Day 1, Story 7\n",
      "Currently Scraping: Day 1, Story 8\n",
      "Currently Scraping: Day 1, Story 9\n",
      "Currently Scraping: Day 1, Story 10\n",
      "Currently Scraping: Day 2, Story 1\n",
      "Currently Scraping: Day 2, Story 2\n",
      "Currently Scraping: Day 2, Story 3\n",
      "Currently Scraping: Day 2, Story 4\n",
      "Currently Scraping: Day 2, Story 5\n",
      "Currently Scraping: Day 2, Story 6\n",
      "Currently Scraping: Day 2, Story 7\n",
      "Currently Scraping: Day 2, Story 8\n",
      "Currently Scraping: Day 2, Story 9\n",
      "Currently Scraping: Day 2, Story 10\n",
      "Currently Scraping: Day 3, Story 1\n",
      "Currently Scraping: Day 3, Story 2\n",
      "Currently Scraping: Day 3, Story 3\n",
      "Currently Scraping: Day 3, Story 4\n",
      "Currently Scraping: Day 3, Story 5\n",
      "Currently Scraping: Day 3, Story 6\n",
      "Currently Scraping: Day 3, Story 7\n",
      "Currently Scraping: Day 3, Story 8\n",
      "Currently Scraping: Day 3, Story 9\n",
      "Currently Scraping: Day 3, Story 10\n",
      "Currently Scraping: Day 4, Story 1\n",
      "Currently Scraping: Day 4, Story 2\n",
      "Currently Scraping: Day 4, Story 3\n",
      "Currently Scraping: Day 4, Story 4\n",
      "Currently Scraping: Day 4, Story 5\n",
      "Currently Scraping: Day 4, Story 6\n",
      "Currently Scraping: Day 4, Story 7\n",
      "Currently Scraping: Day 4, Story 8\n",
      "Currently Scraping: Day 4, Story 9\n",
      "Currently Scraping: Day 4, Story 10\n",
      "Currently Scraping: Day 5, Story 1\n",
      "Currently Scraping: Day 5, Story 2\n",
      "Currently Scraping: Day 5, Story 3\n",
      "Currently Scraping: Day 5, Story 4\n",
      "Currently Scraping: Day 5, Story 5\n",
      "Currently Scraping: Day 5, Story 6\n",
      "Currently Scraping: Day 5, Story 7\n",
      "Currently Scraping: Day 5, Story 8\n",
      "Currently Scraping: Day 5, Story 9\n",
      "Currently Scraping: Day 5, Story 10\n",
      "Currently Scraping: Day 6, Story 1\n",
      "Currently Scraping: Day 6, Story 2\n",
      "Currently Scraping: Day 6, Story 3\n",
      "Currently Scraping: Day 6, Story 4\n",
      "Currently Scraping: Day 6, Story 5\n",
      "Currently Scraping: Day 6, Story 6\n",
      "Currently Scraping: Day 6, Story 7\n",
      "Currently Scraping: Day 6, Story 8\n",
      "Currently Scraping: Day 6, Story 9\n",
      "Currently Scraping: Day 6, Story 10\n",
      "Currently Scraping: Day 7, Story 1\n",
      "Currently Scraping: Day 7, Story 2\n",
      "Currently Scraping: Day 7, Story 3\n",
      "Currently Scraping: Day 7, Story 4\n",
      "Currently Scraping: Day 7, Story 5\n",
      "Currently Scraping: Day 7, Story 6\n",
      "Currently Scraping: Day 7, Story 7\n",
      "Currently Scraping: Day 7, Story 8\n",
      "Currently Scraping: Day 7, Story 9\n",
      "Currently Scraping: Day 7, Story 10\n",
      "Currently Scraping: Day 8, Story 1\n",
      "Currently Scraping: Day 8, Story 2\n",
      "Currently Scraping: Day 8, Story 3\n",
      "Currently Scraping: Day 8, Story 4\n",
      "Currently Scraping: Day 8, Story 5\n",
      "Currently Scraping: Day 8, Story 6\n",
      "Currently Scraping: Day 8, Story 7\n",
      "Currently Scraping: Day 8, Story 8\n",
      "Currently Scraping: Day 8, Story 9\n",
      "Currently Scraping: Day 8, Story 10\n",
      "Currently Scraping: Day 9, Story 1\n",
      "Currently Scraping: Day 9, Story 2\n",
      "Currently Scraping: Day 9, Story 3\n",
      "Currently Scraping: Day 9, Story 4\n",
      "Currently Scraping: Day 9, Story 5\n",
      "Currently Scraping: Day 9, Story 6\n",
      "Currently Scraping: Day 9, Story 7\n",
      "Currently Scraping: Day 9, Story 8\n",
      "Currently Scraping: Day 9, Story 9\n",
      "Currently Scraping: Day 9, Story 10\n",
      "Currently Scraping: Day 10, Story 1\n",
      "Currently Scraping: Day 10, Story 2\n",
      "Currently Scraping: Day 10, Story 3\n",
      "Currently Scraping: Day 10, Story 4\n",
      "Currently Scraping: Day 10, Story 5\n",
      "Currently Scraping: Day 10, Story 6\n",
      "Currently Scraping: Day 10, Story 7\n",
      "Currently Scraping: Day 10, Story 8\n",
      "Currently Scraping: Day 10, Story 9\n",
      "Currently Scraping: Day 10, Story 10\n"
     ]
    }
   ],
   "source": [
    "# this creates a 2d array of all the stories\n",
    "stories_all = []\n",
    "for day in np.arange(1, 11, 1):\n",
    "    day_stories = []\n",
    "    for story in np.arange(1, 11, 1):\n",
    "        print(f\"Currently Scraping: Day {day}, Story {story}\")\n",
    "        day_stories.append(clean_story(return_URL(day, story)))\n",
    "    stories_all.append(day_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e017a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'thou', 'one', 'said', 'thy', 'tis', 'thee']\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "annoying_words = [\"thou\", \"one\", \"said\", \"thy\", \"tis\", \"thee\"]\n",
    "stop_words += annoying_words\n",
    "print(stop_words)\n",
    "texts = [[word for word in simple_preprocess(str(story)) if word not in stop_words] for story in stories_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "#num_topics = 10\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=10, random_state=42, passes=50, alpha=\"auto\", per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aebab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.008*\"lady\" + 0.006*\"would\" + 0.005*\"might\" + 0.004*\"love\" + 0.004*\"time\" '\n",
      "  '+ 0.004*\"made\" + 0.004*\"great\" + 0.004*\"man\" + 0.004*\"well\" + 0.004*\"come\"'),\n",
      " (1,\n",
      "  '0.000*\"lady\" + 0.000*\"would\" + 0.000*\"well\" + 0.000*\"might\" + 0.000*\"love\" '\n",
      "  '+ 0.000*\"man\" + 0.000*\"wherefore\" + 0.000*\"good\" + 0.000*\"made\" + '\n",
      "  '0.000*\"upon\"'),\n",
      " (2,\n",
      "  '0.000*\"would\" + 0.000*\"might\" + 0.000*\"man\" + 0.000*\"lady\" + 0.000*\"messer\" '\n",
      "  '+ 0.000*\"made\" + 0.000*\"well\" + 0.000*\"time\" + 0.000*\"upon\" + 0.000*\"love\"'),\n",
      " (3,\n",
      "  '0.000*\"lady\" + 0.000*\"would\" + 0.000*\"made\" + 0.000*\"love\" + 0.000*\"great\" '\n",
      "  '+ 0.000*\"might\" + 0.000*\"wherefore\" + 0.000*\"never\" + 0.000*\"man\" + '\n",
      "  '0.000*\"may\"'),\n",
      " (4,\n",
      "  '0.010*\"messer\" + 0.006*\"king\" + 0.006*\"lady\" + 0.006*\"torello\" + '\n",
      "  '0.006*\"made\" + 0.005*\"love\" + 0.005*\"would\" + 0.005*\"might\" + 0.005*\"wife\" '\n",
      "  '+ 0.004*\"great\"'),\n",
      " (5,\n",
      "  '0.007*\"man\" + 0.006*\"god\" + 0.006*\"would\" + 0.005*\"ciappelletto\" + '\n",
      "  '0.005*\"ser\" + 0.005*\"great\" + 0.004*\"good\" + 0.004*\"thus\" + 0.004*\"made\" + '\n",
      "  '0.004*\"abbot\"'),\n",
      " (6,\n",
      "  '0.000*\"lady\" + 0.000*\"would\" + 0.000*\"might\" + 0.000*\"good\" + 0.000*\"time\" '\n",
      "  '+ 0.000*\"calandrino\" + 0.000*\"well\" + 0.000*\"thus\" + 0.000*\"god\" + '\n",
      "  '0.000*\"upon\"'),\n",
      " (7,\n",
      "  '0.014*\"lady\" + 0.008*\"husband\" + 0.007*\"would\" + 0.006*\"might\" + '\n",
      "  '0.005*\"quoth\" + 0.004*\"come\" + 0.004*\"know\" + 0.004*\"wife\" + 0.004*\"well\" + '\n",
      "  '0.004*\"house\"'),\n",
      " (8,\n",
      "  '0.000*\"would\" + 0.000*\"lady\" + 0.000*\"might\" + 0.000*\"great\" + 0.000*\"time\" '\n",
      "  '+ 0.000*\"love\" + 0.000*\"well\" + 0.000*\"thus\" + 0.000*\"man\" + 0.000*\"upon\"'),\n",
      " (9,\n",
      "  '0.010*\"lady\" + 0.007*\"would\" + 0.005*\"god\" + 0.005*\"may\" + 0.005*\"love\" + '\n",
      "  '0.004*\"well\" + 0.004*\"might\" + 0.004*\"shall\" + 0.004*\"know\" + '\n",
      "  '0.004*\"tedaldo\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91a2a625",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29600a01",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
